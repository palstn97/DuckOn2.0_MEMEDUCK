# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# íŒŒì´í”„ë¼ì¸ ìƒì„± ì¡°ê±´
#  - MR íƒ€ê²Ÿì´ master â†’ ë¹Œë“œë§Œ
#  - master ì— push/merge â†’ ë¹Œë“œ í›„ ë°°í¬
#  - MR íƒ€ê²Ÿì´ develop â†’ ë¹Œë“œë§Œ 
#  - develop ì— push/merge â†’ ë¹Œë“œ/ë°°í¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
workflow:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master"'
    - if: '$CI_COMMIT_BRANCH == "master"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "develop"'
    - if: '$CI_COMMIT_BRANCH == "develop"'
    - when: never

stages: [build, deploy]

# ì „ì—­ ë³€ìˆ˜
variables:
  BE_APP: "duckon-app-prod"
  FE_APP: "duckon-front-prod"
  BE_APP_DEV: "duckon-app-dev"
  FE_APP_DEV: "duckon-front-dev"
  GIT_DEPTH: "10"
  GRADLE_USER_HOME: "$CI_PROJECT_DIR/.gradle"

cache:
  key: "$CI_COMMIT_REF_SLUG"
  paths:
    - .gradle/caches/
    - .gradle/wrapper/
    - frontend/node_modules/
    - md_frontend/node_modules/
  policy: pull-push

# ëŸ¬ë„ˆ íƒœê·¸
.default_tags: &default_tags
  tags: ["duckon","dind"]

# AWS CLI + jq ê³µí†µ before_script (ë©€í‹°ë¼ì¸ ìŠ¤í¬ë¦½íŠ¸)
.before_aws_cli: &before_aws_cli |
  set -eo pipefail
  curl -L -o /usr/local/bin/jq "https://github.com/jqlang/jq/releases/download/jq-1.7.1/jq-linux-amd64"
  chmod +x /usr/local/bin/jq

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# BE ë¹Œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
build_backend:
  stage: build
  <<: *default_tags
  rules:
    - changes:
        - backend/**/*
        - build.gradle*
        - settings.gradle*
        - gradle/**/*
        - .gitlab-ci.yml
    - when: never
  image: gradle:8.6-jdk21
  variables:
    GRADLE_USER_HOME: "$CI_PROJECT_DIR/.gradle"
  script:
    - cd backend
    - chmod +x ./gradlew || true
    - |
      if [ "$CI_PIPELINE_SOURCE" = "merge_request_event" ]; then
        ./gradlew --build-cache --configuration-cache assemble -x test
      else
        ./gradlew --build-cache --configuration-cache clean build
      fi

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FE ë¹Œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
build_frontend:
  stage: build
  tags: ["duckon","dind"]
  image: node:20-alpine
  rules:
    # FE ê´€ë ¨ ë³€ê²½ ìˆì„ ë•Œë§Œ ì‹¤í–‰
    - changes:
        - frontend/**/*
        - frontend/package.json
        - frontend/package-lock.json
        - frontend/vite.config.* 
        - .gitlab-ci.yml
    - when: never
  script:
    - cd frontend
    - npm ci --prefer-offline --no-audit --progress=false
    - |
      if [ "$CI_COMMIT_BRANCH" = "master" ] || [ "$CI_MERGE_REQUEST_TARGET_BRANCH_NAME" = "master" ]; then
        API_BASE="${VITE_API_BASE_URL_PROD:-/api}"
      else
        API_BASE="${VITE_API_BASE_URL_DEV:-/api}"
      fi
      VITE_API_BASE_URL="$API_BASE" VITE_YOUTUBE_API_KEY="$VITE_YOUTUBE_API_KEY" npm run build --silent
  artifacts:
    paths:
      - frontend/dist
    expire_in: 1 week

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PROD: í”„ë¡ íŠ¸ (S3+CloudFront)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
deploy_frontend_prod:
  stage: deploy
  tags: ["duckon","dind"]
  image:
    name: amazon/aws-cli:2.17.60
    entrypoint: ["/bin/bash","-lc"]
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "master"'
      changes:
        - frontend/**/*
        - frontend/package.json
        - frontend/package-lock.json
        - frontend/vite.config.*
        - .gitlab-ci.yml
    - when: never
  needs:
    - job: build_frontend
      artifacts: true
  before_script:
    - *before_aws_cli
    - '[ -n "$AWS_ACCESS_KEY_ID_PROD" ] || { echo "Missing AWS creds"; exit 1; }'
    - '[ -n "$AWS_SECRET_ACCESS_KEY_PROD" ] || { echo "Missing AWS creds"; exit 1; }'
    - '[ -n "$AWS_REGION_PROD" ] || { echo "Missing region"; exit 1; }'
    - '[ -n "$S3_BUCKET_FE_PROD" ] || { echo "Missing S3 bucket"; exit 1; }'
    - '[ -n "$CF_DISTRIBUTION_ID_PROD" ] || { echo "Missing CF dist id"; exit 1; }'
    - export AWS_ACCESS_KEY_ID="$AWS_ACCESS_KEY_ID_PROD"
    - export AWS_SECRET_ACCESS_KEY="$AWS_SECRET_ACCESS_KEY_PROD"
    - export AWS_DEFAULT_REGION="$AWS_REGION_PROD"
  script: |
    cd frontend/dist
    aws s3 cp . "s3://$S3_BUCKET_FE_PROD" --recursive \
      --exclude "*.html" \
      --cache-control "public,max-age=31536000,immutable"
    find . -name "*.html" -print0 | while IFS= read -r -d '' f; do
      aws s3 cp "$f" "s3://$S3_BUCKET_FE_PROD/${f#./}" \
        --cache-control "no-cache" \
        --content-type "text/html; charset=utf-8"
    done
    aws cloudfront create-invalidation \
      --distribution-id "$CF_DISTRIBUTION_ID_PROD" \
      --paths "/index.html" "/"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PROD: ë°±ì—”ë“œ (SSM)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
deploy_backend_prod:
  stage: deploy
  tags: ["duckon","dind"]
  image:
    name: amazon/aws-cli:2.17.60
    entrypoint: ["/bin/bash","-lc"]
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "master"'
    - when: never
  # ğŸ”§ ì—¬ê¸° ìˆ˜ì •: build_backend ê°€ ì—†ì„ ë•Œë„ íŒŒì´í”„ë¼ì¸ì´ ìƒì„±ë˜ë„ë¡ optional needs ì‚¬ìš©
  needs:
    - job: build_backend
      optional: true
  before_script:
    - *before_aws_cli
    - '[ -n "$AWS_ACCESS_KEY_ID_PROD" ] || { echo "Missing: AWS_ACCESS_KEY_ID_PROD"; exit 1; }'
    - '[ -n "$AWS_SECRET_ACCESS_KEY_PROD" ] || { echo "Missing: AWS_SECRET_ACCESS_KEY_PROD"; exit 1; }'
    - '[ -n "$AWS_REGION_PROD" ] || { echo "Missing: AWS_REGION_PROD"; exit 1; }'
    - '[ -n "$PROD_INSTANCE_ID" ] || { echo "Missing: PROD_INSTANCE_ID"; exit 1; }'
    - export AWS_ACCESS_KEY_ID="$AWS_ACCESS_KEY_ID_PROD"
    - export AWS_SECRET_ACCESS_KEY="$AWS_SECRET_ACCESS_KEY_PROD"
    - export AWS_DEFAULT_REGION="$AWS_REGION_PROD"
    - aws sts get-caller-identity
  script: |
    cat > remote.sh <<'EOS'
    set -eux

    NET=""
    if docker inspect duckon-proxy >/dev/null 2>&1; then
      NET=$(docker inspect -f '{{range $k,$v := .NetworkSettings.Networks}}{{printf "%s " $k}}{{end}}' duckon-proxy | awk '{print $1}')
    fi
    if [ -z "$NET" ]; then
      if docker network ls --format '{{.Name}}' | grep -q '^duckon-net$'; then
        NET="duckon-net"
      else
        docker network create duckon-net >/dev/null 2>&1 || true
        NET="duckon-net"
      fi
    fi
    echo "[NET] $NET"

    WORKDIR="/srv/duckon/repo/S13P31A406"
    mkdir -p "$WORKDIR"; cd "$WORKDIR"

    ORIGIN="https://gitlab-ci-token:__CI_JOB_TOKEN__@__CI_SERVER_HOST__/__CI_PROJECT_PATH__.git"
    COMMIT="__CI_COMMIT_SHA__"
    BE_APP="__BE_APP__"

    if [ -d .git ]; then
      git remote set-url origin "$ORIGIN"
      git fetch --all --prune
    else
      git init
      git remote add origin "$ORIGIN"
      git fetch origin
    fi
    git reset --hard "$COMMIT"
    echo "[git] HEAD=$(git rev-parse --short HEAD)"

    ENV_FILE="/srv/duckon/compose/prod.env"
    [ -f "$ENV_FILE" ] || { echo "[ERROR] $ENV_FILE not found"; exit 23; }

    echo "[BE] build & restart"
    docker build -t duckonback:prod -f backend/Dockerfile backend
    docker rm -f "$BE_APP" 2>/dev/null || true
    docker run -d --name "$BE_APP" \
      --network "$NET" \
      --env-file "$ENV_FILE" \
      -e SPRING_PROFILES_ACTIVE=prod \
      -e JAVA_OPTS="-Xms256m -Xmx512m" \
      --restart unless-stopped \
      duckonback:prod

    docker ps --format 'table {{.Names}}\t{{.Image}}\t{{.Status}}\t{{.Ports}}'

    echo "[healthcheck]"
    i=1
    while [ $i -le 30 ]; do
      code=$(curl -ksS -o /dev/null -w "%{http_code}" https://duckon.site/api/actuator/health || true)
      [ "$code" = "200" ] || [ "$code" = "401" ] && { echo "OK ($code)"; exit 0; }
      echo "retry $i/30"; i=$((i+1)); sleep 3
    done
    echo "healthcheck failed"; exit 31
    EOS

    sed -i \
      -e "s|__CI_JOB_TOKEN__|$CI_JOB_TOKEN|g" \
      -e "s|__CI_SERVER_HOST__|$CI_SERVER_HOST|g" \
      -e "s|__CI_PROJECT_PATH__|$CI_PROJECT_PATH|g" \
      -e "s|__CI_COMMIT_SHA__|$CI_COMMIT_SHA|g" \
      -e "s|__BE_APP__|$BE_APP|g" \
      remote.sh

    jq -n --arg script "$(cat remote.sh)" '{commands: [$script]}' > ssm-params.json

    CMD_ID=$(aws ssm send-command \
      --instance-ids "$PROD_INSTANCE_ID" \
      --document-name "AWS-RunShellScript" \
      --comment "DuckOn prod deploy $CI_COMMIT_SHA" \
      --parameters file://ssm-params.json \
      --query "Command.CommandId" --output text)
    echo "CommandId: $CMD_ID"

    while :; do
      OUT=$(aws ssm get-command-invocation \
        --command-id "$CMD_ID" \
        --instance-id "$PROD_INSTANCE_ID" \
        --output json || true)
      STATUS=$(echo "$OUT" | jq -r '.Status // empty')
      echo "SSM: ${STATUS:-unknown}"
      [ "$STATUS" = "Pending" ] || [ "$STATUS" = "InProgress" ] || [ "$STATUS" = "Delayed" ] || [ -z "$STATUS" ] && { sleep 3; continue; }
      echo "----- STDOUT -----"; echo "$OUT" | jq -r '.StandardOutputContent // ""'
      echo "----- STDERR -----"; echo "$OUT" | jq -r '.StandardErrorContent // ""'
      [ "$STATUS" = "Success" ] && exit 0 || exit 1
    done

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DEV ë°°í¬ (SSH/PEM) + ë””ìŠ¤í¬ ì •ë¦¬ ìë™í™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
deploy_dev:
  stage: deploy
  <<: *default_tags
  image: alpine:3.20
  rules:
    # develop ë¸Œëœì¹˜ì— push/merge ë˜ì—ˆì„ ë•Œë§Œ ë°°í¬
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "develop"'
    - when: never
  needs:
    - job: build_backend
      optional: true
  before_script:
    - set -euxo pipefail
    - apk add --no-cache openssh-client bash git jq curl
    # í•„ìˆ˜ ë³€ìˆ˜ ì²´í¬
    - '[ -n "$DEV_HOST" ] || { echo "Missing CI var: DEV_HOST"; exit 1; }'
    - '[ -n "$DEV_USER" ] || { echo "Missing CI var: DEV_USER"; exit 1; }'
    - '[ -n "$DEV_SSH_KEY" ] || { echo "Missing CI var: DEV_SSH_KEY"; exit 1; }'
    # SSH í‚¤ ì €ì¥
    - mkdir -p ~/.ssh
    - echo "$DEV_SSH_KEY" | tr -d '\r' > ~/.ssh/duckon-dev.pem
    - chmod 600 ~/.ssh/duckon-dev.pem
    - printf "Host dev-host\n  HostName %s\n  User %s\n  IdentityFile %s\n  StrictHostKeyChecking no\n" "$DEV_HOST" "$DEV_USER" "~/.ssh/duckon-dev.pem" > ~/.ssh/config
  script: |
    # ì›ê²©ì—ì„œ ì‹¤í–‰í•  ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë§Œë“ ë‹¤
    cat > remote-dev.sh <<'EOS'
    set -eux

    echo "[maintenance] docker prune on dev"
    docker builder prune -a -f || true
    docker container prune -f || true
    docker image prune -a -f || true
    docker volume prune -f || true
    docker network prune -f || true
    docker system df -v || true

    # 1) ë„¤íŠ¸ì›Œí¬ ë³´ì¥
    NET=""
    if docker network ls --format '{{.Name}}' | grep -q '^duckon-dev$'; then
      NET="duckon-dev"
    else
      docker network create duckon-dev >/dev/null 2>&1 || true
      NET="duckon-dev"
    fi
    echo "[NET] $NET"

    # 2) ì‘ì—… ë””ë ‰í† ë¦¬
    WORKDIR="/home/$USER/repos/duckon"
    mkdir -p "$WORKDIR"; cd "$WORKDIR"

    # 3) Git ìµœì‹  ì†ŒìŠ¤(í† í°ìœ¼ë¡œ read)
    ORIGIN="https://gitlab-ci-token:__CI_JOB_TOKEN__@__CI_SERVER_HOST__/__CI_PROJECT_PATH__.git"
    COMMIT="__CI_COMMIT_SHA__"

    if [ -d .git ]; then
      git remote set-url origin "$ORIGIN"
    else
      git init
      git remote add origin "$ORIGIN"
    fi

    # CI_COMMIT_SHAë¥¼ ì§ì ‘ fetch í•´ì„œ í•´ë‹¹ ì»¤ë°‹ì´ ë¡œì»¬ì— ì¡´ì¬í•˜ë„ë¡ ë³´ì¥
    if ! git fetch origin "$COMMIT"; then
      echo "[WARN] direct fetch of $COMMIT failed, fallback to full fetch"
      git fetch --all --prune
    fi

    # ì»¤ë°‹ì´ ì‹¤ì œë¡œ ë‚´ë ¤ì™€ ìˆëŠ”ì§€ í™•ì¸
    if ! git cat-file -e "$COMMIT"^{commit}; then
      echo "[ERROR] Commit $COMMIT not found after fetch"
      echo "[HINT] ë¸Œëœì¹˜/ê¶Œí•œ/ì €ì¥ì†Œ ì„¤ì • í™•ì¸ í•„ìš”"
      exit 42
    fi

    # í•´ë‹¹ ì»¤ë°‹ ê¸°ì¤€ìœ¼ë¡œ develop ë¸Œëœì¹˜ë¥¼ ê°•ì œë¡œ ë§ì¶¤
    git checkout -B develop "$COMMIT"
    echo "[git] HEAD=$(git rev-parse --short HEAD)"

    # 4) Backend ë¹Œë“œ/ì‹¤í–‰
    echo "[BE] build & restart (dev)"
    docker build -t duckonback:dev -f backend/Dockerfile backend
    docker rm -f "__BE_APP_DEV__" 2>/dev/null || true
    # dev.env íŒŒì¼ì€ ë ˆí¬ì— ì¡´ì¬ (backend/dev.env)
    docker run -d --name "__BE_APP_DEV__" \
      --network "$NET" \
      --env-file backend/dev.env \
      -e SPRING_PROFILES_ACTIVE=dev \
      -e JAVA_OPTS="-Xms256m -Xmx512m" \
      --restart unless-stopped \
      duckonback:dev

    # 5) Frontend ë¹Œë“œ/ì‹¤í–‰ (nginx.dev.conf ë§ˆìš´íŠ¸)
    echo "[FE] build & restart (dev)"
    docker build \
      --pull --no-cache \
      --build-arg VITE_API_BASE_URL="__VITE_API_BASE_URL_DEV__" \
      --build-arg VITE_YOUTUBE_API_KEY="__VITE_YOUTUBE_API_KEY__" \
      --build-arg BUILD_NOCACHE="$(date +%s)" \
      -t duckon-front:dev \
      -f frontend/Dockerfile frontend

    docker rm -f "__FE_APP_DEV__" 2>/dev/null || true
    docker run -d --name "__FE_APP_DEV__" \
      --network "$NET" \
      -p 80:80 \
      -v "$WORKDIR/frontend/nginx.dev.conf:/etc/nginx/conf.d/default.conf:ro" \
      --restart unless-stopped \
      duckon-front:dev

    # (ì„ íƒ) DB/ìºì‹œ ì»¨í…Œì´ë„ˆê°€ ìˆë‹¤ë©´ ë„¤íŠ¸ì›Œí¬ì— ì—°ê²°
    for S in mysql-dev redis-dev duckon-mongo-dev; do
      docker network connect "$NET" "$S" 2>/dev/null || true
    done

    echo "[ps]"
    docker ps --format 'table {{.Names}}\t{{.Image}}\t{{.Status}}\t{{.Ports}}'

    echo "[healthcheck: FE 80]"
    code=$(curl -s -o /dev/null -w '%{http_code}' http://localhost/)
    echo "HTTP $code"
    [ "$code" = "200" ] || [ "$code" = "301" ] || [ "$code" = "302" ] || exit 31
    EOS

    # í† í°/ë³€ìˆ˜ ì¹˜í™˜
    sed -i \
      -e "s|__CI_JOB_TOKEN__|$CI_JOB_TOKEN|g" \
      -e "s|__CI_SERVER_HOST__|$CI_SERVER_HOST|g" \
      -e "s|__CI_PROJECT_PATH__|$CI_PROJECT_PATH|g" \
      -e "s|__CI_COMMIT_SHA__|$CI_COMMIT_SHA|g" \
      -e "s|__BE_APP_DEV__|$BE_APP_DEV|g" \
      -e "s|__FE_APP_DEV__|$FE_APP_DEV|g" \
      -e "s|__VITE_API_BASE_URL_DEV__|${VITE_API_BASE_URL_DEV:-/api}|g" \
      -e "s|__VITE_YOUTUBE_API_KEY__|${VITE_YOUTUBE_API_KEY:-}|g" \
      remote-dev.sh

    # ì›ê²© ì‹¤í–‰
    scp -q remote-dev.sh dev-host:/tmp/remote-dev.sh
    ssh dev-host "bash /tmp/remote-dev.sh && rm -f /tmp/remote-dev.sh"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Memeduck Frontend (Vite) â€” masterâ†’PROD, developâ†’DEV
#  - MR(ëŒ€ìƒ master/develop): ë¹Œë“œë§Œ
#  - master/develop push(=merge í¬í•¨): ë¹Œë“œ í›„ ë°°í¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

.variables_memeduck: &vars_memeduck
  MD_FE_DIR: "md_frontend"

# 1) Build (MR/Push ëª¨ë‘)
build_memeduck_front:
  stage: build
  <<: *default_tags
  image: node:20-alpine
  variables:
    <<: *vars_memeduck
  rules:
    - changes:
        - md_frontend/**/*
        - md_frontend/package.json
        - md_frontend/package-lock.json
        - md_frontend/vite.config.*
        - .gitlab-ci.yml
    - when: never
  script:
    - cd "$MD_FE_DIR"
    - npm ci
    - |
      # ë¸Œëœì¹˜/íƒ€ê²Ÿì— ë”°ë¼ API Base ì„¤ì •
      if [ "$CI_COMMIT_BRANCH" = "master" ] || [ "$CI_MERGE_REQUEST_TARGET_BRANCH_NAME" = "master" ]; then
        API_BASE="${VITE_API_BASE_URL_MD_PROD:-/api}"
      else
        API_BASE="${VITE_API_BASE_URL_MD_DEV:-/api}"
      fi
      echo "VITE_API_BASE_URL_MD=$API_BASE"
      VITE_API_BASE_URL_MD="$API_BASE" npm run build
  artifacts:
    paths:
      - $MD_FE_DIR/dist
    expire_in: 1 week

# 2) Deploy to DEV (develop push/merge)
deploy_memeduck_front_dev:
  stage: deploy
  <<: *default_tags
  image:
    name: amazon/aws-cli:2.17.60
    entrypoint: ["/bin/bash","-lc"]
  variables:
    <<: *vars_memeduck
  needs:
    - job: build_memeduck_front
      artifacts: true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "develop"'
      changes:
        - md_frontend/**/*
        - md_frontend/package.json
        - md_frontend/package-lock.json
        - md_frontend/vite.config.*
        - .gitlab-ci.yml
    - when: never
  before_script:
    - *before_aws_cli
    - '[ -n "$AWS_ACCESS_KEY_ID_PROD" ] || { echo "Missing AWS creds"; exit 1; }'
    - '[ -n "$AWS_SECRET_ACCESS_KEY_PROD" ] || { echo "Missing AWS creds"; exit 1; }'
    - '[ -n "$AWS_REGION_PROD" ] || { echo "Missing region"; exit 1; }'
    - '[ -n "$S3_BUCKET_MD_FE_DEV" ] || { echo "Missing S3 bucket (DEV)"; exit 1; }'
    - '[ -n "$CF_DISTRIBUTION_ID_MD_FE_DEV" ] || { echo "Missing CF dist id (DEV)"; exit 1; }'
    - export AWS_ACCESS_KEY_ID="$AWS_ACCESS_KEY_ID_PROD"
    - export AWS_SECRET_ACCESS_KEY="$AWS_SECRET_ACCESS_KEY_PROD"
    - export AWS_DEFAULT_REGION="$AWS_REGION_PROD"
  script: |
    cd "$MD_FE_DIR/dist"
    # ì •ì  ë¦¬ì†ŒìŠ¤(HTML ì œì™¸)ëŠ” ì¥ê¸° ìºì‹œ
    aws s3 cp . "s3://$S3_BUCKET_MD_FE_DEV" --recursive \
      --exclude "*.html" \
      --cache-control "public,max-age=31536000,immutable"
    # HTMLì€ no-cache
    find . -name "*.html" -print0 | while IFS= read -r -d '' f; do
      aws s3 cp "$f" "s3://$S3_BUCKET_MD_FE_DEV/${f#./}" \
        --cache-control "no-cache" \
        --content-type "text/html; charset=utf-8"
    done
    # CF ìºì‹œ ë¬´íš¨í™”
    aws cloudfront create-invalidation \
      --distribution-id "$CF_DISTRIBUTION_ID_MD_FE_DEV" \
      --paths "/index.html" "/"

# 3) Deploy to PROD (master push/merge)
deploy_memeduck_front_prod:
  stage: deploy
  <<: *default_tags
  image:
    name: amazon/aws-cli:2.17.60
    entrypoint: ["/bin/bash","-lc"]
  variables:
    <<: *vars_memeduck
  needs:
    - job: build_memeduck_front
      artifacts: true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "master"'
      changes:
        - md_frontend/**/*
        - md_frontend/package.json
        - md_frontend/package-lock.json
        - md_frontend/vite.config.*
        - .gitlab-ci.yml
    - when: never
  before_script:
    - *before_aws_cli
    - '[ -n "$AWS_ACCESS_KEY_ID_PROD" ] || { echo "Missing AWS creds"; exit 1; }'
    - '[ -n "$AWS_SECRET_ACCESS_KEY_PROD" ] || { echo "Missing AWS creds"; exit 1; }'
    - '[ -n "$AWS_REGION_PROD" ] || { echo "Missing region"; exit 1; }'
    - '[ -n "$S3_BUCKET_MD_FE_PROD" ] || { echo "Missing S3 bucket (PROD)"; exit 1; }'
    - '[ -n "$CF_DISTRIBUTION_ID_MD_FE_PROD" ] || { echo "Missing CF dist id (PROD)"; exit 1; }'
    - export AWS_ACCESS_KEY_ID="$AWS_ACCESS_KEY_ID_PROD"
    - export AWS_SECRET_ACCESS_KEY="$AWS_SECRET_ACCESS_KEY_PROD"
    - export AWS_DEFAULT_REGION="$AWS_REGION_PROD"
  script: |
    cd "$MD_FE_DIR/dist"
    aws s3 cp . "s3://$S3_BUCKET_MD_FE_PROD" --recursive \
      --exclude "*.html" \
      --cache-control "public,max-age=31536000,immutable"
    find . -name "*.html" -print0 | while IFS= read -r -d '' f; do
      aws s3 cp "$f" "s3://$S3_BUCKET_MD_FE_PROD/${f#./}" \
        --cache-control "no-cache" \
        --content-type "text/html; charset=utf-8"
    done
    aws cloudfront create-invalidation \
      --distribution-id "$CF_DISTRIBUTION_ID_MD_FE_PROD" \
      --paths "/index.html" "/"
